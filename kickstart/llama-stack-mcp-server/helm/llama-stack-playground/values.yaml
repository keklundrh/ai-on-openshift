# Default values for llama-stack-playground
replicaCount: 1

image:
  repository: quay.io/rh-aiservices-bu/llama-stack-playground
  tag: "0.2.1"
  pullPolicy: IfNotPresent

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

podAnnotations: {}

podSecurityContext:
  runAsNonRoot: true
  # Remove specific UID/GID to let OpenShift assign them
  # fsGroup: 1001

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: false
  runAsNonRoot: true
  # Remove specific UID/GID to let OpenShift assign them
  # runAsUser: 1001
  # runAsGroup: 1001

service:
  type: ClusterIP
  port: 80
  targetPort: 8501
  annotations: {}

route:
  enabled: true
  annotations: {}
  host: ""
  tls:
    enabled: true
    termination: edge
    insecureEdgeTerminationPolicy: Redirect


resources:
  limits:
    cpu: 1000m
    memory: 1Gi
  requests:
    cpu: 500m
    memory: 512Mi

livenessProbe:
  httpGet:
    path: /
    port: http
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /
    port: http
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3

autoscaling:
  enabled: false

nodeSelector: {}

tolerations: []

affinity: {}

# Playground configuration
playground:
  # Llama Stack backend URL
  llamaStackUrl: "http://llama-stack"
  # Default model to use
  defaultModel: "llama3-2-3b"

# Environment variables
env:
  STREAMLIT_SERVER_PORT: "8501"
  STREAMLIT_SERVER_ADDRESS: "0.0.0.0"
  STREAMLIT_BROWSER_GATHER_USAGE_STATS: "false"

